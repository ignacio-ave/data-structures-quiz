{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Generación de texto LLM para Google Colab\n",
        "\n",
        "Este cuaderno utiliza https://github.com/oobabooga/text-generation-webui para ejecutar modelos de conversación en modo de chat.\n",
        "\n",
        "Ejecute todas las celdas y aparecerá una URL pública de gradio en la parte inferior en aproximadamente 5 minutos.\n",
        "\n",
        "https://status.gradio.app/\n",
        "\n",
        "\n",
        "## Parámetros\n",
        "\n",
        "* **save_logs_to_google_drive**: guarda automáticamente los registros de chat, caracteres y softprompts en Google Drive, para que persistan en diferentes sesiones.\n",
        "* **text_streaming**: muestra la salida de texto en tiempo real en lugar de esperar a que se complete la respuesta completa.\n",
        "* **cai_chat**: hace que la interfaz se vea como Character.AI. De lo contrario, se ve como un chat similar a WhatsApp estándar.\n",
        "* **load_in_8bit**: carga el modelo con una precisión de 8 bits, lo que reduce el uso de memoria de la GPU a la mitad. Esto le permite usar la longitud completa de 2048 caracteres sin quedarse sin memoria, a costa de una pequeña disminución de la precisión y la velocidad.\n",
        "* **activate_silero_text_to_speech**:las respuestas serán archivos de audio en lugar de texto. Hay disponibles 118 voces (en_0 a en_117), que se pueden configurar en la pestaña \"Extensiones\" de la interfaz. Puede encontrar ejemplos aquí: [Silero samples](https://oobabooga.github.io/silero-samples/).\n",
        "* **activate_sending_pictures**: agrega un menú para enviar imágenes al bot, que se subtitulan automáticamente utilizando BLIP.\n",
        "* **activate_character_bias**: una extensión que agrega una cadena oculta definida por el usuario al comienzo de la respuesta del bot con el objetivo de sesgar el resto de la respuesta.\n",
        "* **chat_language**: si es diferente al inglés, activa la traducción automática utilizando Google Translate, lo que le permite comunicarse con el bot en un idioma diferente.\n",
        "\n",
        "## Personajes o Agentes\n",
        "\n",
        "You can use the following websites to create characters compatible with this web UI:\n",
        "\n",
        "* [Creador de personajes JSON](https://oobabooga.github.io/character-creator.html)\n",
        "* [Editor de personajes de IA](https://zoltanai.github.io/character-editor/)\n",
        "\n",
        "## Créditos\n",
        "\n",
        "Basado en [notebook original by 81300](https://colab.research.google.com/github/81300/AI-Notebooks/blob/main/Colab-TextGen-GPU.ipynb).\n",
        "Basado en [notebook version 4bits](https://colab.research.google.com/github/pcrii/Philo-Colab-Collection/blob/main/4bit_TextGen_Gdrive.ipynb)."
      ],
      "metadata": {
        "id": "MFQl6-FjSYtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Mantén esta pestaña activa para evitar que Colab te desconecte { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Presiona reproducir en el reproductor de música que aparecerá a continuación:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "f7TVVj_z4flw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Instalar la interfaz web\n",
        "#remember gradio is currently held back\n",
        "save_logs_to_google_drive = False #@param {type:\"boolean\"} \n",
        "save_everything_to_google_drive = False #@param {type:\"boolean\"} \n",
        "#@markdown recuerda que estos modelos son grandes y la capacidad gratuita de Google Drive es solo de 15 GB <br>\n",
        "install_gptq = True #@param {type:\"boolean\"}\n",
        "#@markdown Instalar GPTQ-for-LLaMa para modelos cuantizados de 4 bits que requieren --wbits 4\n",
        "if save_logs_to_google_drive:\n",
        "  import os\n",
        "  import shutil\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  base_folder = '/content/drive/MyDrive'\n",
        "\n",
        "if save_everything_to_google_drive:\n",
        "    import os\n",
        "    import shutil\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base_folder = '/content/drive/MyDrive'\n",
        "    repo_dir = '/content/drive/MyDrive/text-generation-webui'\n",
        "    model_dir = '/content/drive/MyDrive/text-generation-webui/models'\n",
        "    gptq_dir = '/content/drive/MyDrive/text-generation-webui/repositories/GPTQ-for-LLaMa'\n",
        "    if os.path.exists(repo_dir):\n",
        "        %cd {repo_dir}\n",
        "        !git pull\n",
        "    else:\n",
        "        %cd /content/drive/MyDrive/\n",
        "        !git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "else:\n",
        "    model_dir = '/content/text-generation-webui/models'\n",
        "    repo_dir = '/content/text-generation-webui'\n",
        "    %cd /content\n",
        "    !git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "\n",
        "\n",
        "if save_logs_to_google_drive:\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/logs\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data/logs\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/softprompts\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data/softprompts\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/characters\"):\n",
        "    shutil.move(\"text-generation-webui/characters\", f\"{base_folder}/oobabooga-data/characters\")\n",
        "  else:\n",
        "    !rm -r \"text-generation-webui/characters\"\n",
        "    \n",
        "  !rm -r \"text-generation-webui/softprompts\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/logs\" \"text-generation-webui/logs\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/softprompts\" \"text-generation-webui/softprompts\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/characters\" \"text-generation-webui/characters\"\n",
        "\n",
        "else:\n",
        "  !mkdir text-generation-webui/logs\n",
        "\n",
        "!ln -s text-generation-webui/logs .\n",
        "!ln -s text-generation-webui/characters .\n",
        "!ln -s text-generation-webui/models .\n",
        "%rm -r sample_data\n",
        "%cd text-generation-webui\n",
        "!wget https://raw.githubusercontent.com/pcrii/Philo-Colab-Collection/main/settings-colab-template.json -O settings-colab-template.json\n",
        "\n",
        "# Install requirements\n",
        "!pip install -r requirements.txt\n",
        "!pip install -r extensions/google_translate/requirements.txt\n",
        "!pip install -r extensions/silero_tts/requirements.txt\n",
        "print(f\"\\033[1;32;1m\\n --> If you see a warning about \\\"pydevd_plugins\\\", just ignore it and move on to Step 3. There is no need to restart the runtime.\\n\\033[0;37;0m\")\n",
        "\n",
        "if install_gptq:\n",
        "    if save_everything_to_google_drive:\n",
        "        if os.path.exists(gptq_dir):\n",
        "            %cd {gptq_dir}\n",
        "            !git pull\n",
        "            !pip install ninja\n",
        "            !pip install -r requirements.txt\n",
        "            !python setup_cuda.py install\n",
        "\n",
        "        else:\n",
        "            !mkdir /content/drive/MyDrive/text-generation-webui/repositories\n",
        "            %cd /content/drive/MyDrive/text-generation-webui/repositories\n",
        "            !git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "            %cd GPTQ-for-LLaMa\n",
        "            !pip install ninja\n",
        "            !pip install -r requirements.txt\n",
        "            !python setup_cuda.py install\n",
        "    else:\n",
        "        %mkdir /content/text-generation-webui/repositories/\n",
        "        %cd /content/text-generation-webui/repositories/\n",
        "        !git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "        %cd GPTQ-for-LLaMa\n",
        "        !pip install ninja\n",
        "        !pip install -r requirements.txt\n",
        "        !python setup_cuda.py install\n",
        "# clear_output()\n",
        "print(\"Finished\")"
      ],
      "metadata": {
        "id": "LGQ8BiMuXMDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Descargar el modelo\n",
        "#@markdown Puedes insertar cualquier modelo de Hugging Face en el formato Organization/modelo.\n",
        "model_download = \"anon8231489123/vicuna-13b-GPTQ-4bit-128g\" #@param [ \"facebook/opt-1.3b\", \"anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\", \"anon8231489123/vicuna-13b-GPTQ-4bit-128g\"] {allow-input: true}\n",
        "#@markdown  Descarga el modelo\n",
        "%cd {repo_dir}\n",
        "!python download-model.py {model_download}\n",
        "#this lists directorys from your model folder you can copy the name provided for the model you want for use in the the next cell\n",
        "!rm {model_dir}/place-your-models-here.txt\n",
        "# clear_output()\n",
        "if save_logs_to_google_drive or save_everything_to_google_drive:\n",
        "    drive_NOT_mounted = False\n",
        "else:\n",
        "    drive_NOT_mounted = True\n",
        "\n",
        "if drive_NOT_mounted:\n",
        "  import os\n",
        "print(\"Available Models\")\n",
        "print(os.listdir(model_dir))\n",
        "\n"
      ],
      "metadata": {
        "id": "E7t4QfXf4U9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Launch\n",
        "\n",
        "import json\n",
        "\n",
        "#@markdown if you dont know what to enter the previous cell should have printed available inputs <br> paste it here\n",
        "model_load = \"anon8231489123_vicuna-13b-GPTQ-4bit-128g\" #@param {type:\"string\"}\n",
        "# Parameters\n",
        "#auto_devices = False #@param {type:\"boolean\"}\n",
        "load_4bit_models = True #@param {type:\"boolean\"}\n",
        "\n",
        "groupsize_128 = True #@param {type:\"boolean\"}\n",
        "load_in_8bit = False #@param {type:\"boolean\"}\n",
        "chat = True #@param {type:\"boolean\"}\n",
        "\n",
        "text_streaming = True #@param {type:\"boolean\"}\n",
        "activate_silero_text_to_speech = False #@param {type:\"boolean\"}\n",
        "activate_sending_pictures = False #@param {type:\"boolean\"}\n",
        "activate_character_bias = False #@param {type:\"boolean\"}\n",
        "chat_language = \"Spanish\" # @param ['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Azerbaijani', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Bulgarian', 'Catalan', 'Cebuano', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Kurdish', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Myanmar (Burmese)', 'Nepali', 'Norwegian', 'Nyanja (Chichewa)', 'Pashto', 'Persian', 'Polish', 'Portuguese (Portugal, Brazil)', 'Punjabi', 'Romanian', 'Russian', 'Samoan', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala (Sinhalese)', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog (Filipino)', 'Tajik', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Welsh', 'Xhosa', 'Yiddish', 'Yoruba', 'Zulu']\n",
        "\n",
        "\n",
        "activate_google_translate = (chat_language != \"English\")\n",
        "\n",
        "language_codes = {'Afrikaans': 'af', 'Albanian': 'sq', 'Amharic': 'am', 'Arabic': 'ar', 'Armenian': 'hy', 'Azerbaijani': 'az', 'Basque': 'eu', 'Belarusian': 'be', 'Bengali': 'bn', 'Bosnian': 'bs', 'Bulgarian': 'bg', 'Catalan': 'ca', 'Cebuano': 'ceb', 'Chinese (Simplified)': 'zh-CN', 'Chinese (Traditional)': 'zh-TW', 'Corsican': 'co', 'Croatian': 'hr', 'Czech': 'cs', 'Danish': 'da', 'Dutch': 'nl', 'English': 'en', 'Esperanto': 'eo', 'Estonian': 'et', 'Finnish': 'fi', 'French': 'fr', 'Frisian': 'fy', 'Galician': 'gl', 'Georgian': 'ka', 'German': 'de', 'Greek': 'el', 'Gujarati': 'gu', 'Haitian Creole': 'ht', 'Hausa': 'ha', 'Hawaiian': 'haw', 'Hebrew': 'iw', 'Hindi': 'hi', 'Hmong': 'hmn', 'Hungarian': 'hu', 'Icelandic': 'is', 'Igbo': 'ig', 'Indonesian': 'id', 'Irish': 'ga', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jw', 'Kannada': 'kn', 'Kazakh': 'kk', 'Khmer': 'km', 'Korean': 'ko', 'Kurdish': 'ku', 'Kyrgyz': 'ky', 'Lao': 'lo', 'Latin': 'la', 'Latvian': 'lv', 'Lithuanian': 'lt', 'Luxembourgish': 'lb', 'Macedonian': 'mk', 'Malagasy': 'mg', 'Malay': 'ms', 'Malayalam': 'ml', 'Maltese': 'mt', 'Maori': 'mi', 'Marathi': 'mr', 'Mongolian': 'mn', 'Myanmar (Burmese)': 'my', 'Nepali': 'ne', 'Norwegian': 'no', 'Nyanja (Chichewa)': 'ny', 'Pashto': 'ps', 'Persian': 'fa', 'Polish': 'pl', 'Portuguese (Portugal, Brazil)': 'pt', 'Punjabi': 'pa', 'Romanian': 'ro', 'Russian': 'ru', 'Samoan': 'sm', 'Scots Gaelic': 'gd', 'Serbian': 'sr', 'Sesotho': 'st', 'Shona': 'sn', 'Sindhi': 'sd', 'Sinhala (Sinhalese)': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Spanish': 'es', 'Sundanese': 'su', 'Swahili': 'sw', 'Swedish': 'sv', 'Tagalog (Filipino)': 'tl', 'Tajik': 'tg', 'Tamil': 'ta', 'Telugu': 'te', 'Thai': 'th', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Welsh': 'cy', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zulu': 'zu'}\n",
        "\n",
        "\n",
        "%cd {repo_dir}\n",
        "# Applying the selected language and setting the prompt size to 2048\n",
        "# if 8bit mode is selected\n",
        "j = json.loads(open('settings-colab-template.json', 'r').read())\n",
        "j[\"google_translate-language string\"] = language_codes[chat_language]\n",
        "if load_in_8bit:\n",
        "  j[\"chat_prompt_size\"] = 2048\n",
        "with open('settings-colab.json', 'w') as f:\n",
        "  f.write(json.dumps(j, indent=4))\n",
        "\n",
        "params = set()\n",
        "if chat:\n",
        "  params.add('--cai-chat')\n",
        "\n",
        "if load_in_8bit:\n",
        "  params.add('--load-in-8bit')\n",
        "#if auto_devices:\n",
        "#  params.add('--auto-devices')\n",
        "if load_4bit_models:\n",
        "  params.add('--wbits 4')\n",
        "\n",
        "if groupsize_128:\n",
        "  params.add('--groupsize 128')\n",
        "\n",
        "active_extensions = []\n",
        "if activate_sending_pictures:\n",
        "  active_extensions.append('send_pictures')\n",
        "if activate_character_bias:\n",
        "  active_extensions.append('character_bias')\n",
        "if activate_google_translate:\n",
        "  active_extensions.append('google_translate')\n",
        "if activate_silero_text_to_speech:\n",
        "  active_extensions.append('silero_tts')\n",
        "active_extensions.append('gallery')\n",
        "\n",
        "if len(active_extensions) > 0:\n",
        "  params.add(f'--extensions {\" \".join(active_extensions)}')\n",
        "\n",
        "if not text_streaming or activate_google_translate or activate_silero_text_to_speech:\n",
        "  params.add('--no-stream')\n",
        "if activate_character_bias:\n",
        "  params.add('--verbose')\n",
        "\n",
        "# Starting the web UI\n",
        "cmd = f\"python server.py --share --model {model_load} --settings settings-colab.json {' '.join(params)}\"\n",
        "print(cmd)\n",
        "!$cmd"
      ],
      "metadata": {
        "id": "hKuocueuXnm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title optional install \"LLaMa\" character file i found on reddit\n",
        "!wget https://github.com/pcrii/Philo-Colab-Collection/raw/main/llama.json \n",
        "!mv llama.json {repo_dir}/characters\n"
      ],
      "metadata": {
        "id": "xkDjS3c8Pr_3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
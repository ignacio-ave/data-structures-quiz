{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Chat PDF "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependencias:\n",
    "\n",
    "Para vectorizar contenidos: \n",
    "https://github.com/jerryjliu/llama_index/tree/main\n",
    "\n",
    "Para facilitar la interaccion entre programas - modelos - bases de datos - etc : \n",
    "https://github.com/hwchase17/langchain\n",
    "\n",
    "Api Open AI: \n",
    "https://platform.openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manejo de PDFs\n",
    "!pip install PyPDF2\n",
    "\n",
    "# API de OpenAI\n",
    "!pip install openai\n",
    "\n",
    "#Interactuar con LLMs\n",
    "!pip install langchain\n",
    "\n",
    "#Chunks e indexar\n",
    "#Metodo para indexar de manera eficiente la informacion\n",
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Librerias\n",
    "import os\n",
    "import openai\n",
    "\n",
    "# GPTVectorStoreIndex es una clase que indexa los vectores de GPT\n",
    "# SimpleDirectoryReader es una clase que lee los archivos de un directorio\n",
    "# LLMPredictor es una clase que predice los vectores de GPT\n",
    "# ServiceContext es una clase que permite interactuar con el modelo de GPT-2\n",
    "\n",
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, LLMPredictor, ServiceContext\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import textwrap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pagina para generar key: https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cámbiala por tu API de OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer los PDFs en carpeta datos\n",
    "pdf = SimpleDirectoryReader('datos').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir e instanciar el modelo\n",
    "\n",
    "# Temperatura : parámetro que controla la aleatoriedad de las respuestas generadas, donde una temperatura alta produce respuestas más diversas y una temperatura baja produce respuestas más coherentes pero menos variadas.\n",
    "modelo = LLMPredictor(llm=ChatOpenAI(temperature=0.3, model_name='gpt-3.5-turbo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexar el contenido de los PDFs\n",
    "service_context = ServiceContext.from_defaults(llm_predictor=modelo)\n",
    "index = GPTVectorStoreIndex.from_documents(pdf, service_context = service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar el índice a disco para no tener que repetir cada vez\n",
    "#Recordar que necesistaríamos persistir el drive para que lo mantenga\n",
    "# index.save_to_disk('index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar el índice del disco\n",
    "# index = GPTVectorStoreIndex.load_from_disk('index.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El documento trata sobre LangChain, una herramienta de procesamiento de lenguaje natural que permite\n",
      "crear cadenas de herramientas y modelos de lenguaje para interactuar con los usuarios en diferentes\n",
      "contextos y aplicaciones. El documento explica cómo utilizar LangChain para crear cadenas de\n",
      "herramientas, modelos de lenguaje y agentes para interactuar con los usuarios de manera dinámica y\n",
      "personalizada. También se proporcionan ejemplos de cómo utilizar LangChain para crear cadenas de\n",
      "herramientas y modelos de lenguaje para diferentes aplicaciones.\n",
      "\n",
      "Esperando 30 segundos antes de preguntar de nuevo...\n",
      "¿Deseas hacer otra pregunta? (s/n): \n",
      "Sí, un ejemplo de memoria en una cadena o agente sería en un chatbot que recuerda los mensajes\n",
      "anteriores para poder utilizar el contexto y tener una mejor conversación. Esto sería una especie de\n",
      "\"memoria a corto plazo\".\n",
      "\n",
      "Esperando 30 segundos antes de preguntar de nuevo...\n",
      "¿Deseas hacer otra pregunta? (s/n): \n",
      "Un agente en Python es una herramienta que realiza tareas específicas, como una búsqueda en Google o\n",
      "una consulta en una base de datos, y puede recordar información previa para utilizarla en futuras\n",
      "interacciones. En este tutorial, se muestra cómo utilizar agentes a través de la API más simple y de\n",
      "nivel más alto. Los agentes pueden ser extremadamente poderosos cuando se utilizan correctamente.\n",
      "\n",
      "Esperando 30 segundos antes de preguntar de nuevo...\n",
      "¿Deseas hacer otra pregunta? (s/n): \n",
      "Lo siento, pero la información proporcionada no contiene ninguna referencia a una aplicación civil\n",
      "específica de LangChain. Sin embargo, LangChain se puede utilizar en una amplia variedad de\n",
      "aplicaciones, incluyendo chatbots, asistentes virtuales, generación de texto, traducción automática,\n",
      "análisis de sentimientos y más.\n",
      "\n",
      "Esperando 30 segundos antes de preguntar de nuevo...\n",
      "¿Deseas hacer otra pregunta? (s/n): \n",
      "La implementación de asistentes virtuales puede ser muy poderosa si se utiliza correctamente. Un\n",
      "ejemplo de implementación en Python es el uso de la API de OpenAI para crear un chatbot que pueda\n",
      "recordar conversaciones anteriores y utilizar ese contexto para tener una mejor conversación.\n",
      "También se pueden utilizar herramientas como Google Search y bases de datos para obtener información\n",
      "y responder preguntas de manera más efectiva.\n",
      "\n",
      "Esperando 30 segundos antes de preguntar de nuevo...\n",
      "¿Deseas hacer otra pregunta? (s/n): \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    pregunta = input('Escribe tu pregunta: \\n') + \" Responde en español\"\n",
    "    # Hacer la pregunta al índice\n",
    "    respuesta = index.as_query_engine().query(pregunta)\n",
    "    # Imprimir la respuesta\n",
    "    for frase in textwrap.wrap(respuesta.response, width=100):\n",
    "        print(frase)\n",
    "\n",
    "    # Esperar 30 segundos\n",
    "    print(\"\\nEsperando 30 segundos antes de preguntar de nuevo...\")\n",
    "    time.sleep(30)\n",
    "    \n",
    "    # Preguntar si desea continuar o salir\n",
    "    continuar = input(\"¿Deseas hacer otra pregunta? (s/n): \")\n",
    "    print(\"¿Deseas hacer otra pregunta? (s/n): \")\n",
    "    if continuar.lower() != 's':\n",
    "        break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linkografia:\n",
    "\n",
    "DataScience ForBusiness. (24 de abril de 2023). Cómo Usar ChatGPT Sobre Información Interna De Tu Negocio [Video]. YouTube. https://www.youtube.com/watch?v=hVXpAh1FQCQ  \n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

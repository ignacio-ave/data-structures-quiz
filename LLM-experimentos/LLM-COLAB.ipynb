{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQl6-FjSYtY"
      },
      "source": [
        "# Generación de texto LLM para Google Colab (Traducción al español)\n",
        "\n",
        "Este cuaderno utiliza https://github.com/oobabooga/text-generation-webui para ejecutar modelos de conversación en modo de chat.\n",
        "\n",
        "Ejecute todas las celdas y aparecerá una URL pública de gradio en la parte inferior en aproximadamente 5 minutos.\n",
        "\n",
        "https://status.gradio.app/\n",
        "\n",
        "\n",
        "## Parámetros\n",
        "\n",
        "* **save_logs_to_google_drive**: guarda automáticamente los registros de chat, caracteres y softprompts en Google Drive, para que persistan en diferentes sesiones.\n",
        "* **text_streaming**: muestra la salida de texto en tiempo real en lugar de esperar a que se complete la respuesta completa.\n",
        "* **cai_chat**: hace que la interfaz se vea como Character.AI. De lo contrario, se ve como un chat similar a WhatsApp estándar.\n",
        "* **load_in_8bit**: carga el modelo con una precisión de 8 bits, lo que reduce el uso de memoria de la GPU a la mitad. Esto le permite usar la longitud completa de 2048 caracteres sin quedarse sin memoria, a costa de una pequeña disminución de la precisión y la velocidad.\n",
        "* **activate_silero_text_to_speech**:las respuestas serán archivos de audio en lugar de texto. Hay disponibles 118 voces (en_0 a en_117), que se pueden configurar en la pestaña \"Extensiones\" de la interfaz. Puede encontrar ejemplos aquí: [Silero samples](https://oobabooga.github.io/silero-samples/).\n",
        "* **activate_sending_pictures**: agrega un menú para enviar imágenes al bot, que se subtitulan automáticamente utilizando BLIP.\n",
        "* **activate_character_bias**: una extensión que agrega una cadena oculta definida por el usuario al comienzo de la respuesta del bot con el objetivo de sesgar el resto de la respuesta.\n",
        "* **chat_language**: si es diferente al inglés, activa la traducción automática utilizando Google Translate, lo que le permite comunicarse con el bot en un idioma diferente.\n",
        "\n",
        "## Personajes o Agentes\n",
        "\n",
        "You can use the following websites to create characters compatible with this web UI:\n",
        "\n",
        "* [Creador de personajes JSON](https://oobabooga.github.io/character-creator.html)\n",
        "* [Editor de personajes de IA](https://zoltanai.github.io/character-editor/)\n",
        "\n",
        "## Créditos\n",
        "\n",
        "Basado en [notebook original by 81300](https://colab.research.google.com/github/81300/AI-Notebooks/blob/main/Colab-TextGen-GPU.ipynb).\n",
        "Basado en [notebook version 4bits](https://colab.research.google.com/github/pcrii/Philo-Colab-Collection/blob/main/4bit_TextGen_Gdrive.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f7TVVj_z4flw"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (2620814707.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    <audio src=\"https://oobabooga.github.io/silence.m4a\" controls>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#@title 1. Mantén esta pestaña activa para evitar que Colab te desconecte { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Presiona reproducir en el reproductor de música que aparecerá a continuación:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LGQ8BiMuXMDG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content'\n",
            "/workspaces/data-structures-quiz\n",
            "Cloning into 'text-generation-webui'...\n",
            "remote: Enumerating objects: 7275, done.\u001b[K\n",
            "remote: Counting objects: 100% (1579/1579), done.\u001b[K\n",
            "remote: Compressing objects: 100% (169/169), done.\u001b[K\n",
            "remote: Total 7275 (delta 1462), reused 1436 (delta 1410), pack-reused 5696\u001b[K\n",
            "Receiving objects: 100% (7275/7275), 2.56 MiB | 14.62 MiB/s, done.\n",
            "Resolving deltas: 100% (4858/4858), done.\n",
            "rm: cannot remove 'sample_data': No such file or directory\n",
            "/workspaces/data-structures-quiz/text-generation-webui\n",
            "--2023-05-15 02:59:41--  https://raw.githubusercontent.com/pcrii/Philo-Colab-Collection/main/settings-colab-template.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1039 (1.0K) [text/plain]\n",
            "Saving to: ‘settings-colab-template.json’\n",
            "\n",
            "settings-colab-temp 100%[===================>]   1.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-15 02:59:41 (60.8 MB/s) - ‘settings-colab-template.json’ saved [1039/1039]\n",
            "\n",
            "Collecting git+https://github.com/huggingface/peft (from -r requirements.txt (line 17))\n",
            "  Cloning https://github.com/huggingface/peft to /tmp/pip-req-build-1ywpu7w5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft /tmp/pip-req-build-1ywpu7w5\n",
            "  Resolved https://github.com/huggingface/peft to commit 4fd374e80d670781c0d82c96ce94d1215ff23306\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hIgnoring llama-cpp-python: markers 'platform_system == \"Windows\"' don't match your environment\n",
            "Collecting accelerate==0.19.0 (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: colorama in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.4.6)\n",
            "Collecting datasets (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flexgen==0.1.7 (from -r requirements.txt (line 4))\n",
            "  Downloading flexgen-0.1.7-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio_client==0.1.4 (from -r requirements.txt (line 5))\n",
            "  Downloading gradio_client-0.1.4-py3-none-any.whl (286 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/286.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.25.0 (from -r requirements.txt (line 6))\n",
            "  Downloading gradio-3.25.0-py3-none-any.whl (17.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting markdown (from -r requirements.txt (line 7))\n",
            "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (2.0.1)\n",
            "Requirement already satisfied: Pillow>=9.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (9.5.0)\n",
            "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (6.0)\n",
            "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.28.2)\n",
            "Collecting rwkv==0.7.3 (from -r requirements.txt (line 13))\n",
            "  Downloading rwkv-0.7.3-py3-none-any.whl (16 kB)\n",
            "Collecting safetensors==0.3.1 (from -r requirements.txt (line 14))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from -r requirements.txt (line 15))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/python/3.10.4/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (4.65.0)\n",
            "Collecting transformers==4.28.1 (from -r requirements.txt (line 18))\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.38.1 (from -r requirements.txt (line 19))\n",
            "  Downloading bitsandbytes-0.38.1-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting llama-cpp-python==0.1.50 (from -r requirements.txt (line 20))\n",
            "  Downloading llama_cpp_python-0.1.50.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.10/site-packages (from accelerate==0.19.0->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.10/site-packages (from accelerate==0.19.0->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /home/codespace/.local/lib/python3.10/site-packages (from accelerate==0.19.0->-r requirements.txt (line 1)) (2.0.0)\n",
            "Collecting pulp (from flexgen==0.1.7->-r requirements.txt (line 4))\n",
            "  Downloading PuLP-2.7.0-py3-none-any.whl (14.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /home/codespace/.local/lib/python3.10/site-packages (from flexgen==0.1.7->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/python/3.10.4/lib/python3.10/site-packages (from gradio_client==0.1.4->-r requirements.txt (line 5)) (2023.5.0)\n",
            "Collecting httpx (from gradio_client==0.1.4->-r requirements.txt (line 5))\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from gradio_client==0.1.4->-r requirements.txt (line 5)) (0.14.1)\n",
            "Requirement already satisfied: typing-extensions in /home/codespace/.local/lib/python3.10/site-packages (from gradio_client==0.1.4->-r requirements.txt (line 5)) (4.5.0)\n",
            "Collecting websockets (from gradio_client==0.1.4->-r requirements.txt (line 5))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiofiles in /home/codespace/.local/lib/python3.10/site-packages (from gradio==3.25.0->-r requirements.txt (line 6)) (22.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/python/3.10.4/lib/python3.10/site-packages (from gradio==3.25.0->-r requirements.txt (line 6)) (3.8.4)\n",
            "Collecting altair>=4.2.0 (from gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading altair-5.0.0-py3-none-any.whl (477 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m477.4/477.4 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from gradio==3.25.0->-r requirements.txt (line 6)) (3.1.2)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markupsafe in /home/codespace/.local/lib/python3.10/site-packages (from gradio==3.25.0->-r requirements.txt (line 6)) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.10/site-packages (from gradio==3.25.0->-r requirements.txt (line 6)) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson (from gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading orjson-3.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/python/3.10.4/lib/python3.10/site-packages (from gradio==3.25.0->-r requirements.txt (line 6)) (1.10.7)\n",
            "Collecting pydub (from gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version (from gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting uvicorn (from gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from rwkv==0.7.3->-r requirements.txt (line 13)) (0.13.3)\n",
            "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 18)) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from transformers==4.28.1->-r requirements.txt (line 18)) (2023.5.5)\n",
            "Collecting pyarrow>=8.0.0 (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading pyarrow-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7,>=0.3.0 (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 9)) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 9)) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests->-r requirements.txt (line 12)) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests->-r requirements.txt (line 12)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests->-r requirements.txt (line 12)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests->-r requirements.txt (line 12)) (2022.12.7)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /home/codespace/.local/lib/python3.10/site-packages (from altair>=4.2.0->gradio==3.25.0->-r requirements.txt (line 6)) (4.17.3)\n",
            "Collecting toolz (from altair>=4.2.0->gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->gradio==3.25.0->-r requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->gradio==3.25.0->-r requirements.txt (line 6)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->gradio==3.25.0->-r requirements.txt (line 6)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->gradio==3.25.0->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->gradio==3.25.0->-r requirements.txt (line 6)) (1.3.1)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py[linkify]>=2.0.0->gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: wheel in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (0.40.0)\n",
            "Requirement already satisfied: cmake in /home/codespace/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (3.26.3)\n",
            "Requirement already satisfied: lit in /home/codespace/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (16.0.2)\n",
            "Collecting starlette<0.27.0,>=0.26.1 (from fastapi->gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio_client==0.1.4->-r requirements.txt (line 5))\n",
            "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /home/codespace/.local/lib/python3.10/site-packages (from httpx->gradio_client==0.1.4->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->gradio==3.25.0->-r requirements.txt (line 6)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->gradio==3.25.0->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->gradio==3.25.0->-r requirements.txt (line 6)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->gradio==3.25.0->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib->gradio==3.25.0->-r requirements.txt (line 6)) (3.0.9)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from uvicorn->gradio==3.25.0->-r requirements.txt (line 6)) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn->gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /home/codespace/.local/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio_client==0.1.4->-r requirements.txt (line 5)) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/codespace/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.25.0->-r requirements.txt (line 6)) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.25.0->-r requirements.txt (line 6))\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate==0.19.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: llama-cpp-python, peft, ffmpy\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.50-cp310-cp310-linux_x86_64.whl size=203749 sha256=32c52fdc046840cb9dd7cc062145ef6594f7488bb82252846b5748a2894d79ec\n",
            "  Stored in directory: /home/codespace/.cache/pip/wheels/ed/26/7a/d5f3e9cc210a00274eb9648b6d7d530ae2923b57c43b408a5e\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for peft: filename=peft-0.4.0.dev0-py3-none-any.whl size=56306 sha256=0894d0e34c554c1e85eddb79f1fd8e91bd4c7c68955e5e17f7738eb9ebb4bf73\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1yu9hjar/wheels/4c/16/67/1002a2d4daa822eff130e6d85b90051b75d2ce0d26b9448e4a\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=a63ac7997e7d95419897761f8473d0b52ebdf4882ea68b54c1c96cf0d52af4c2\n",
            "  Stored in directory: /home/codespace/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built llama-cpp-python peft ffmpy\n",
            "Installing collected packages: sentencepiece, safetensors, pydub, pulp, ffmpy, bitsandbytes, xxhash, websockets, uc-micro-py, toolz, semantic-version, rwkv, python-multipart, pyarrow, orjson, mdurl, markdown, llama-cpp-python, h11, dill, uvicorn, starlette, responses, multiprocess, markdown-it-py, linkify-it-py, httpcore, transformers, mdit-py-plugins, httpx, fastapi, altair, gradio_client, datasets, gradio, accelerate, peft, flexgen\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.29.1\n",
            "    Uninstalling transformers-4.29.1:\n",
            "      Successfully uninstalled transformers-4.29.1\n",
            "Successfully installed accelerate-0.19.0 altair-5.0.0 bitsandbytes-0.38.1 datasets-2.12.0 dill-0.3.6 fastapi-0.95.1 ffmpy-0.3.0 flexgen-0.1.7 gradio-3.25.0 gradio_client-0.1.4 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 linkify-it-py-2.0.2 llama-cpp-python-0.1.50 markdown-3.4.3 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 mdurl-0.1.2 multiprocess-0.70.14 orjson-3.8.12 peft-0.4.0.dev0 pulp-2.7.0 pyarrow-12.0.0 pydub-0.25.1 python-multipart-0.0.6 responses-0.18.0 rwkv-0.7.3 safetensors-0.3.1 semantic-version-2.10.0 sentencepiece-0.1.99 starlette-0.26.1 toolz-0.12.0 transformers-4.28.1 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 xxhash-3.2.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
            "Collecting deep-translator==1.9.2 (from -r extensions/google_translate/requirements.txt (line 1))\n",
            "  Downloading deep_translator-1.9.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /home/codespace/.local/lib/python3.10/site-packages (from deep-translator==1.9.2->-r extensions/google_translate/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /home/codespace/.local/lib/python3.10/site-packages (from deep-translator==1.9.2->-r extensions/google_translate/requirements.txt (line 1)) (2.28.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator==1.9.2->-r extensions/google_translate/requirements.txt (line 1)) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator==1.9.2->-r extensions/google_translate/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator==1.9.2->-r extensions/google_translate/requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator==1.9.2->-r extensions/google_translate/requirements.txt (line 1)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator==1.9.2->-r extensions/google_translate/requirements.txt (line 1)) (2022.12.7)\n",
            "Installing collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.9.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: ipython in /home/codespace/.local/lib/python3.10/site-packages (from -r extensions/silero_tts/requirements.txt (line 1)) (8.12.0)\n",
            "Collecting num2words (from -r extensions/silero_tts/requirements.txt (line 2))\n",
            "  Downloading num2words-0.5.12-py3-none-any.whl (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf (from -r extensions/silero_tts/requirements.txt (line 3))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydub in /usr/local/python/3.10.4/lib/python3.10/site-packages (from -r extensions/silero_tts/requirements.txt (line 4)) (0.25.1)\n",
            "Requirement already satisfied: PyYAML in /home/codespace/.local/lib/python3.10/site-packages (from -r extensions/silero_tts/requirements.txt (line 5)) (6.0)\n",
            "Requirement already satisfied: backcall in /home/codespace/.local/lib/python3.10/site-packages (from ipython->-r extensions/silero_tts/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.10/site-packages (from ipython->-r extensions/silero_tts/requirements.txt (line 1)) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /home/codespace/.local/lib/python3.10/site-packages (from ipython->-r extensions/silero_tts/requirements.txt (line 1)) (0.18.2)\n",
            "Requirement already satisfied: matplotlib-inline in /home/codespace/.local/lib/python3.10/site-packages (from ipython->-r extensions/silero_tts/requirements.txt (line 1)) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /home/codespace/.local/lib/python3.10/site-packages (from ipython->-r extensions/silero_tts/requirements.txt (line 1)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/codespace/.local/lib/python3.10/site-packages (from ipython->-r extensions/silero_tts/requirements.txt (line 1)) (3.0.38)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from ipython->-r extensions/silero_tts/requirements.txt (line 1)) (2.15.1)\n",
            "Requirement already satisfied: stack-data in /home/codespace/.local/lib/python3.10/site-packages (from ipython->-r extensions/silero_tts/requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: traitlets>=5 in /home/codespace/.local/lib/python3.10/site-packages (from ipython->-r extensions/silero_tts/requirements.txt (line 1)) (5.9.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /home/codespace/.local/lib/python3.10/site-packages (from ipython->-r extensions/silero_tts/requirements.txt (line 1)) (4.8.0)\n",
            "Collecting docopt>=0.6.2 (from num2words->-r extensions/silero_tts/requirements.txt (line 2))\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from omegaconf->-r extensions/silero_tts/requirements.txt (line 3))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /home/codespace/.local/lib/python3.10/site-packages (from jedi>=0.16->ipython->-r extensions/silero_tts/requirements.txt (line 1)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /home/codespace/.local/lib/python3.10/site-packages (from pexpect>4.3->ipython->-r extensions/silero_tts/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython->-r extensions/silero_tts/requirements.txt (line 1)) (0.2.6)\n",
            "Requirement already satisfied: executing>=1.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from stack-data->ipython->-r extensions/silero_tts/requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from stack-data->ipython->-r extensions/silero_tts/requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: pure-eval in /home/codespace/.local/lib/python3.10/site-packages (from stack-data->ipython->-r extensions/silero_tts/requirements.txt (line 1)) (0.2.2)\n",
            "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython->-r extensions/silero_tts/requirements.txt (line 1)) (1.16.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, docopt\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=4bdb04c3a61496f724cea953b6e9be27cf0875afffca7a02d78f2c26b1c7229a\n",
            "  Stored in directory: /home/codespace/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13707 sha256=30c2329dc46cee7c7958d69ce3c029ee9332e756c6e590f34a00f423e5e16c20\n",
            "  Stored in directory: /home/codespace/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built antlr4-python3-runtime docopt\n",
            "Installing collected packages: docopt, antlr4-python3-runtime, omegaconf, num2words\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 docopt-0.6.2 num2words-0.5.12 omegaconf-2.3.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
            "\u001b[1;32;1m\n",
            " --> If you see a warning about \"pydevd_plugins\", just ignore it and move on to Step 3. There is no need to restart the runtime.\n",
            "\u001b[0;37;0m\n",
            "mkdir: cannot create directory ‘/content/text-generation-webui/repositories/’: No such file or directory\n",
            "[Errno 2] No such file or directory: '/content/text-generation-webui/repositories/'\n",
            "/workspaces/data-structures-quiz/text-generation-webui\n",
            "Cloning into 'GPTQ-for-LLaMa'...\n",
            "remote: Enumerating objects: 814, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 814 (delta 101), reused 97 (delta 97), pack-reused 702\u001b[K\n",
            "Receiving objects: 100% (814/814), 468.00 KiB | 14.62 MiB/s, done.\n",
            "Resolving deltas: 100% (494/494), done.\n",
            "/workspaces/data-structures-quiz/text-generation-webui/GPTQ-for-LLaMa\n",
            "Collecting ninja\n",
            "  Using cached ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "Installing collected packages: ninja\n",
            "Successfully installed ninja-1.11.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
            "Collecting safetensors==0.3.0 (from -r requirements.txt (line 1))\n",
            "  Downloading safetensors-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting datasets==2.10.1 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/python/3.10.4/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.1.99)\n",
            "Collecting transformers==4.28.0 (from -r requirements.txt (line 4))\n",
            "  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hCollecting accelerate==0.18.0 (from -r requirements.txt (line 5))\n",
            "  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/codespace/.local/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (12.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.3.6)\n",
            "Requirement already satisfied: pandas in /home/codespace/.local/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /home/codespace/.local/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (2.28.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/python/3.10.4/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/python/3.10.4/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (2023.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/python/3.10.4/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.14.1)\n",
            "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.10/site-packages (from datasets==2.10.1->-r requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.10/site-packages (from transformers==4.28.0->-r requirements.txt (line 4)) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from transformers==4.28.0->-r requirements.txt (line 4)) (2023.5.5)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from transformers==4.28.0->-r requirements.txt (line 4)) (0.13.3)\n",
            "Requirement already satisfied: psutil in /home/codespace/.local/lib/python3.10/site-packages (from accelerate==0.18.0->-r requirements.txt (line 5)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from accelerate==0.18.0->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.4/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/codespace/.local/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1->-r requirements.txt (line 2)) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1->-r requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1->-r requirements.txt (line 2)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1->-r requirements.txt (line 2)) (2022.12.7)\n",
            "Requirement already satisfied: sympy in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: wheel in /home/codespace/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (0.40.0)\n",
            "Requirement already satisfied: cmake in /home/codespace/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (3.26.3)\n",
            "Requirement already satisfied: lit in /home/codespace/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (16.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 2)) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/codespace/.local/lib/python3.10/site-packages (from pandas->datasets==2.10.1->-r requirements.txt (line 2)) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.10.1->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/codespace/.local/lib/python3.10/site-packages (from sympy->torch>=1.4.0->accelerate==0.18.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Installing collected packages: safetensors, transformers, datasets, accelerate\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.3.1\n",
            "    Uninstalling safetensors-0.3.1:\n",
            "      Successfully uninstalled safetensors-0.3.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.28.1\n",
            "    Uninstalling transformers-4.28.1:\n",
            "      Successfully uninstalled transformers-4.28.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.12.0\n",
            "    Uninstalling datasets-2.12.0:\n",
            "      Successfully uninstalled datasets-2.12.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.19.0\n",
            "    Uninstalling accelerate-0.19.0:\n",
            "      Successfully uninstalled accelerate-0.19.0\n",
            "Successfully installed accelerate-0.18.0 datasets-2.10.1 safetensors-0.3.0 transformers-4.28.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/workspaces/data-structures-quiz/text-generation-webui/GPTQ-for-LLaMa/setup_cuda.py\", line 6, in <module>\n",
            "    ext_modules=[cpp_extension.CUDAExtension(\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1048, in CUDAExtension\n",
            "    library_dirs += library_paths(cuda=True)\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 1179, in library_paths\n",
            "    if (not os.path.exists(_join_cuda_home(lib_dir)) and\n",
            "  File \"/home/codespace/.local/lib/python3.10/site-packages/torch/utils/cpp_extension.py\", line 2223, in _join_cuda_home\n",
            "    raise EnvironmentError('CUDA_HOME environment variable is not set. '\n",
            "OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
            "Finished\n"
          ]
        }
      ],
      "source": [
        "#@title 2. Instalar la interfaz web\n",
        "#remember gradio is currently held back\n",
        "save_logs_to_google_drive = False #@param {type:\"boolean\"} \n",
        "save_everything_to_google_drive = False #@param {type:\"boolean\"} \n",
        "#@markdown recuerda que estos modelos son grandes y la capacidad gratuita de Google Drive es solo de 15 GB <br>\n",
        "install_gptq = True #@param {type:\"boolean\"}\n",
        "#@markdown Instalar GPTQ-for-LLaMa para modelos cuantizados de 4 bits que requieren --wbits 4\n",
        "if save_logs_to_google_drive:\n",
        "  import os\n",
        "  import shutil\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  base_folder = '/content/drive/MyDrive'\n",
        "\n",
        "if save_everything_to_google_drive:\n",
        "    import os\n",
        "    import shutil\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base_folder = '/content/drive/MyDrive'\n",
        "    repo_dir = '/content/drive/MyDrive/text-generation-webui'\n",
        "    model_dir = '/content/drive/MyDrive/text-generation-webui/models'\n",
        "    gptq_dir = '/content/drive/MyDrive/text-generation-webui/repositories/GPTQ-for-LLaMa'\n",
        "    if os.path.exists(repo_dir):\n",
        "        %cd {repo_dir}\n",
        "        !git pull\n",
        "    else:\n",
        "        %cd /content/drive/MyDrive/\n",
        "        !git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "else:\n",
        "    model_dir = '/content/text-generation-webui/models'\n",
        "    repo_dir = '/content/text-generation-webui'\n",
        "    %cd /content\n",
        "    !git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "\n",
        "\n",
        "if save_logs_to_google_drive:\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/logs\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data/logs\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/softprompts\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data/softprompts\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/characters\"):\n",
        "    shutil.move(\"text-generation-webui/characters\", f\"{base_folder}/oobabooga-data/characters\")\n",
        "  else:\n",
        "    !rm -r \"text-generation-webui/characters\"\n",
        "    \n",
        "  !rm -r \"text-generation-webui/softprompts\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/logs\" \"text-generation-webui/logs\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/softprompts\" \"text-generation-webui/softprompts\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/characters\" \"text-generation-webui/characters\"\n",
        "\n",
        "else:\n",
        "  !mkdir text-generation-webui/logs\n",
        "\n",
        "!ln -s text-generation-webui/logs .\n",
        "!ln -s text-generation-webui/characters .\n",
        "!ln -s text-generation-webui/models .\n",
        "%rm -r sample_data\n",
        "%cd text-generation-webui\n",
        "!wget https://raw.githubusercontent.com/pcrii/Philo-Colab-Collection/main/settings-colab-template.json -O settings-colab-template.json\n",
        "\n",
        "# Install requirements\n",
        "!pip install -r requirements.txt\n",
        "!pip install -r extensions/google_translate/requirements.txt\n",
        "!pip install -r extensions/silero_tts/requirements.txt\n",
        "print(f\"\\033[1;32;1m\\n --> If you see a warning about \\\"pydevd_plugins\\\", just ignore it and move on to Step 3. There is no need to restart the runtime.\\n\\033[0;37;0m\")\n",
        "\n",
        "if install_gptq:\n",
        "    if save_everything_to_google_drive:\n",
        "        if os.path.exists(gptq_dir):\n",
        "            %cd {gptq_dir}\n",
        "            !git pull\n",
        "            !pip install ninja\n",
        "            !pip install -r requirements.txt\n",
        "            !python setup_cuda.py install\n",
        "\n",
        "        else:\n",
        "            !mkdir /content/drive/MyDrive/text-generation-webui/repositories\n",
        "            %cd /content/drive/MyDrive/text-generation-webui/repositories\n",
        "            !git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "            %cd GPTQ-for-LLaMa\n",
        "            !pip install ninja\n",
        "            !pip install -r requirements.txt\n",
        "            !python setup_cuda.py install\n",
        "    else:\n",
        "        %mkdir /content/text-generation-webui/repositories/\n",
        "        %cd /content/text-generation-webui/repositories/\n",
        "        !git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "        %cd GPTQ-for-LLaMa\n",
        "        !pip install ninja\n",
        "        !pip install -r requirements.txt\n",
        "        !python setup_cuda.py install\n",
        "# clear_output()\n",
        "print(\"Finished\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E7t4QfXf4U9p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/text-generation-webui'\n",
            "/workspaces/data-structures-quiz/text-generation-webui/GPTQ-for-LLaMa\n",
            "python: can't open file '/workspaces/data-structures-quiz/text-generation-webui/GPTQ-for-LLaMa/download-model.py': [Errno 2] No such file or directory\n",
            "rm: cannot remove '/content/text-generation-webui/models/place-your-models-here.txt': No such file or directory\n",
            "Available Models\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/text-generation-webui/models'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAvailable Models\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[39mprint\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(model_dir))\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/text-generation-webui/models'"
          ]
        }
      ],
      "source": [
        "#@title Descargar el modelo\n",
        "#@markdown Puedes insertar cualquier modelo de Hugging Face en el formato Organization/modelo.\n",
        "model_download = \"anon8231489123/vicuna-13b-GPTQ-4bit-128g\" #@param [ \"facebook/opt-1.3b\", \"anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\", \"anon8231489123/vicuna-13b-GPTQ-4bit-128g\"] {allow-input: true}\n",
        "#@markdown  Descarga el modelo\n",
        "%cd {repo_dir}\n",
        "!python download-model.py {model_download}\n",
        "#this lists directorys from your model folder you can copy the name provided for the model you want for use in the the next cell\n",
        "!rm {model_dir}/place-your-models-here.txt\n",
        "# clear_output()\n",
        "if save_logs_to_google_drive or save_everything_to_google_drive:\n",
        "    drive_NOT_mounted = False\n",
        "else:\n",
        "    drive_NOT_mounted = True\n",
        "\n",
        "if drive_NOT_mounted:\n",
        "  import os\n",
        "print(\"Available Models\")\n",
        "print(os.listdir(model_dir))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKuocueuXnm5"
      },
      "outputs": [],
      "source": [
        "#@title 3. Launch\n",
        "\n",
        "import json\n",
        "\n",
        "#@markdown if you dont know what to enter the previous cell should have printed available inputs <br> paste it here\n",
        "model_load = \"anon8231489123_vicuna-13b-GPTQ-4bit-128g\" #@param {type:\"string\"}\n",
        "# Parameters\n",
        "#auto_devices = False #@param {type:\"boolean\"}\n",
        "load_4bit_models = True #@param {type:\"boolean\"}\n",
        "\n",
        "groupsize_128 = True #@param {type:\"boolean\"}\n",
        "load_in_8bit = False #@param {type:\"boolean\"}\n",
        "chat = True #@param {type:\"boolean\"}\n",
        "\n",
        "text_streaming = True #@param {type:\"boolean\"}\n",
        "activate_silero_text_to_speech = False #@param {type:\"boolean\"}\n",
        "activate_sending_pictures = False #@param {type:\"boolean\"}\n",
        "activate_character_bias = False #@param {type:\"boolean\"}\n",
        "chat_language = \"Spanish\" # @param ['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Azerbaijani', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Bulgarian', 'Catalan', 'Cebuano', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Kurdish', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Myanmar (Burmese)', 'Nepali', 'Norwegian', 'Nyanja (Chichewa)', 'Pashto', 'Persian', 'Polish', 'Portuguese (Portugal, Brazil)', 'Punjabi', 'Romanian', 'Russian', 'Samoan', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala (Sinhalese)', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog (Filipino)', 'Tajik', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Welsh', 'Xhosa', 'Yiddish', 'Yoruba', 'Zulu']\n",
        "\n",
        "\n",
        "activate_google_translate = (chat_language != \"English\")\n",
        "\n",
        "language_codes = {'Afrikaans': 'af', 'Albanian': 'sq', 'Amharic': 'am', 'Arabic': 'ar', 'Armenian': 'hy', 'Azerbaijani': 'az', 'Basque': 'eu', 'Belarusian': 'be', 'Bengali': 'bn', 'Bosnian': 'bs', 'Bulgarian': 'bg', 'Catalan': 'ca', 'Cebuano': 'ceb', 'Chinese (Simplified)': 'zh-CN', 'Chinese (Traditional)': 'zh-TW', 'Corsican': 'co', 'Croatian': 'hr', 'Czech': 'cs', 'Danish': 'da', 'Dutch': 'nl', 'English': 'en', 'Esperanto': 'eo', 'Estonian': 'et', 'Finnish': 'fi', 'French': 'fr', 'Frisian': 'fy', 'Galician': 'gl', 'Georgian': 'ka', 'German': 'de', 'Greek': 'el', 'Gujarati': 'gu', 'Haitian Creole': 'ht', 'Hausa': 'ha', 'Hawaiian': 'haw', 'Hebrew': 'iw', 'Hindi': 'hi', 'Hmong': 'hmn', 'Hungarian': 'hu', 'Icelandic': 'is', 'Igbo': 'ig', 'Indonesian': 'id', 'Irish': 'ga', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jw', 'Kannada': 'kn', 'Kazakh': 'kk', 'Khmer': 'km', 'Korean': 'ko', 'Kurdish': 'ku', 'Kyrgyz': 'ky', 'Lao': 'lo', 'Latin': 'la', 'Latvian': 'lv', 'Lithuanian': 'lt', 'Luxembourgish': 'lb', 'Macedonian': 'mk', 'Malagasy': 'mg', 'Malay': 'ms', 'Malayalam': 'ml', 'Maltese': 'mt', 'Maori': 'mi', 'Marathi': 'mr', 'Mongolian': 'mn', 'Myanmar (Burmese)': 'my', 'Nepali': 'ne', 'Norwegian': 'no', 'Nyanja (Chichewa)': 'ny', 'Pashto': 'ps', 'Persian': 'fa', 'Polish': 'pl', 'Portuguese (Portugal, Brazil)': 'pt', 'Punjabi': 'pa', 'Romanian': 'ro', 'Russian': 'ru', 'Samoan': 'sm', 'Scots Gaelic': 'gd', 'Serbian': 'sr', 'Sesotho': 'st', 'Shona': 'sn', 'Sindhi': 'sd', 'Sinhala (Sinhalese)': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Spanish': 'es', 'Sundanese': 'su', 'Swahili': 'sw', 'Swedish': 'sv', 'Tagalog (Filipino)': 'tl', 'Tajik': 'tg', 'Tamil': 'ta', 'Telugu': 'te', 'Thai': 'th', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Welsh': 'cy', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zulu': 'zu'}\n",
        "\n",
        "\n",
        "%cd {repo_dir}\n",
        "# Applying the selected language and setting the prompt size to 2048\n",
        "# if 8bit mode is selected\n",
        "j = json.loads(open('settings-colab-template.json', 'r').read())\n",
        "j[\"google_translate-language string\"] = language_codes[chat_language]\n",
        "if load_in_8bit:\n",
        "  j[\"chat_prompt_size\"] = 2048\n",
        "with open('settings-colab.json', 'w') as f:\n",
        "  f.write(json.dumps(j, indent=4))\n",
        "\n",
        "params = set()\n",
        "if chat:\n",
        "  params.add('--cai-chat')\n",
        "\n",
        "if load_in_8bit:\n",
        "  params.add('--load-in-8bit')\n",
        "#if auto_devices:\n",
        "#  params.add('--auto-devices')\n",
        "if load_4bit_models:\n",
        "  params.add('--wbits 4')\n",
        "\n",
        "if groupsize_128:\n",
        "  params.add('--groupsize 128')\n",
        "\n",
        "active_extensions = []\n",
        "if activate_sending_pictures:\n",
        "  active_extensions.append('send_pictures')\n",
        "if activate_character_bias:\n",
        "  active_extensions.append('character_bias')\n",
        "if activate_google_translate:\n",
        "  active_extensions.append('google_translate')\n",
        "if activate_silero_text_to_speech:\n",
        "  active_extensions.append('silero_tts')\n",
        "active_extensions.append('gallery')\n",
        "\n",
        "if len(active_extensions) > 0:\n",
        "  params.add(f'--extensions {\" \".join(active_extensions)}')\n",
        "\n",
        "if not text_streaming or activate_google_translate or activate_silero_text_to_speech:\n",
        "  params.add('--no-stream')\n",
        "if activate_character_bias:\n",
        "  params.add('--verbose')\n",
        "\n",
        "# Starting the web UI\n",
        "cmd = f\"python server.py --share --model {model_load} --settings settings-colab.json {' '.join(params)}\"\n",
        "print(cmd)\n",
        "!$cmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkDjS3c8Pr_3"
      },
      "outputs": [],
      "source": [
        "#@title optional install \"LLaMa\" character file i found on reddit\n",
        "!wget https://github.com/pcrii/Philo-Colab-Collection/raw/main/llama.json \n",
        "!mv llama.json {repo_dir}/characters\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
